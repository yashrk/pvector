\input texinfo
@documentencoding UTF-8
@settitle @code{pvector} — pure Scheme persistent vector implementation

@titlepage
@title @code{pvector} — pure Scheme persistent vector implementation
@end titlepage

@contents

@node Top
@top pvector

Pure Scheme persistent vector implementation.

@node Motivation
@chapter Motivation

@section Why?

The lack of an efficient Clojure-like purely functional vector in the Guile Scheme standard library has always been a pain point for me. However, the idea of a bit-partitioned vector trie is very beautiful and relatively simple. So once I decided to implement it myself.

@section Sources of inspiration

@itemize @bullet
    @item
    Persistent vector implementation in Cloure by Rich Hickey: @url{https://github.com/clojure/clojure/blob/master/test/clojure/test_clojure/vectors.clj}

    @item
    Persistent vector implementation in Racket by Alexis King: @url{https://github.com/lexi-lambda/racket-pvector/tree/master}

    @item
    Blog post series «Understanding Clojure's Persistent Vectors» by Jean Niklas L'Orange:

    @itemize @minus

        @item
        @url{https://hypirion.com/musings/understanding-persistent-vector-pt-1}

        @item
        @url{https://hypirion.com/musings/understanding-persistent-vector-pt-2}

        @item
        @url{https://hypirion.com/musings/understanding-persistent-vector-pt-3}

        @item
        @url{https://hypirion.com/musings/understanding-clojure-transients}

        @item
        @url{https://hypirion.com/musings/persistent-vector-performance}

        @item
        @url{https://hypirion.com/musings/persistent-vector-performance-summarised}

    @end itemize

    @item
    A talk «Postmodern immutable data structures» by Juan Pedro Bolivar Puente at CppCon 2017: @url{https://www.youtube.com/watch?v=sPhpelUfu8Q}

@end itemize

@node How it works
@chapter Basic principles

@section Representing vector as a wide shallow tree

The simpliest way to store a vector is by using an array (reallocated quantum satis). However, this representation is incompatible with immutability: any write operation (changing an element, adding a new element, removing an element) will result in @math{O(n)} steps (where @math{n} is the number of elements in the vector). So, this naïve implementation would be unacceptably slow.

The most common approach to inventing persistent data structures (popularized by Chris Okasaki in his PhD thesis@footnote{Purely Functional Data Structures by Chris Okasaki, Carnegie Mellon University, Pittsburgh, 1996; see also his book with the same name — Purely Functional Data Structures, Cambridge University Press, 1999}) is to store values in a tree and to copy (on write) only the target tree leaf and the path to that leaf. This method can also be applied to persistent vectors.

@center @image{vector-as-a-shallow-tree, 395.5pt, 178.5pt, vector as a shallow tree}

@center @it{Vector of 14 elements as a shallow tree.}
@center @it{My reporoduction of a picture by Jean Niklas L'Orange}
@center @it{from @url{https://hypirion.com/musings/understanding-persistent-vector-pt-1}}

We can store the vector as a collection of small arrays, which form the leaves of a tree. So, any single-element operation such as accessing by index, replacement, pushing, or popping will require @math{O(\log_m n)} steps, where @math{n} is the vector size and @math{m} is the branching factor of the tree. Notably, these trees can be very broad and thus very shallow: while a binary tree representing a vector with 1,000,000 elements would have @math{\lceil \log_2(1000000)\rceil + 1 = 21} levels, a 32-ary tree would have only @math{\lceil \log_{32}(1000000)\rceil + 1 = 5} levels.

The @code{pvector} library uses 32-ary trees.

@section Implicit sharing

A purely functional structure never changes. Instead of modifying existing values, we create new versions by copying old values. This approach allows parts that are common between the old and new versions of the structure to be safely shared, ensuring efficient use of memory.

@center @image{implicit-sharing, 417.9pt, 349.3pt, implicit sharing}

@center @it{My reporoduction of a picture by Jean Niklas L'Orange}
@center @it{from @url{https://hypirion.com/musings/understanding-persistent-vector-pt-1}}

In the illustration, the new vector (blue) uses orange (old) nodes for all values, not visited during the update. This approach significantly optimizes memory usage. See @url{https://www.youtube.com/watch?v=sPhpelUfu8Q} for an example of editing a file larger than the available memory.

@section Index bits as a route in a tree

We can view our tree of arrays as a @emph{trie} — a key-value data structure where the key is represented as a path to the given node. In a tree with a branching factor of @math{m}, the index in a positional numeral system with radix @math{m} describes a path to an element. Specifically, the leftmost digit indicates the zero-based index of the root's children, the next digit determines which child node to choose at level 2, and so on, with the rightmost digit representing the target element's index within the leaf.

Imagine we store a vector with 9,457 elements in a 7-ary tree and we should get an element with the index 9,128. Our tree will have @math{\lceil \log_7 9457\rceil = 5} intermediate levels (we will choose the path in the tree 5 times). To navigate through this structure, we need to transorm our index to the 7-digit system: @math{9457 = 35420_7}.

@center @image{index-7-digit-number-system, 464pt, 216pt, 7-digit index}
@center @it{My reporoduction of a picture by Jean Niklas L'Orange}
@center @it{from @url{https://hypirion.com/musings/understanding-persistent-vector-pt-2}}

The base-7 representation can now guide our path through the tree. At any level @math{i} (enumerated from the @emph{leaves} level, zero-based) we can obtain the @math{i}-th digit by performing integer division by @math{7^i} to remove the least significant digits, then taking the reminder from the division by @math{7} to get current digit. This digit will indicate the target branch at the current level.

@math{\lfloor 35420_7 / (7_{10})^4 \rfloor = \lfloor 35420_7 / 10000_7 \rfloor = 3_7}, no need to get a reminder,

@math{\lfloor 35420_7 / (7_{10})^3 \rfloor = \lfloor 35420_7 / 1000_7 \rfloor = 35_7}, @math{35_7 \mathbin{\%} 7_{10} = 5_7}

@math{\lfloor 35420_7 / (7_{10})^2 \rfloor = \lfloor 35420_7 / 100_7 \rfloor = 354_7}, @math{354_7 \mathbin{\%} 7_{10} = 4_7}

@math{\lfloor 35420_7 / (7_{10})^1 \rfloor = \lfloor 35420_7 / 10_7 \rfloor = 3542_7}, @math{3542_7 \mathbin{\%} 7_{10} = 2_7}

@math{\lfloor 35420_7 / (7_{10})^0 \rfloor = \lfloor 35420_7 / 1 \rfloor = 35420_7}, @math{35420_7 \mathbin{\%} 7_{10} = 0_7}

The only drawback is that integer division and modulo operations are relatively slow.

However, if the branching factor is a power of two, these operations can be optimized. We can perform the integer division using a bit shift by the bit size of the branching factor, and the reminder can be calculated using a bitwise AND with a number that is one less than the branching factor (essentially, a number composed of all bit 1-s in all significant bits). These bitwise operations are very fast on modern computers.

@center @image{index-binary-system, 430.5pt, 226pt, binary index}
@center @it{My reporoduction of a picture by Jean Niklas L'Orange}
@center @it{from @url{https://hypirion.com/musings/understanding-persistent-vector-pt-2}}

Thus, the search within the tree can be implemented using the following algorithm (for simplicity's sake, let's consider an imperative version):

@center @image{index-binary-system-flowchart, 242.8pt, 408.4pt, binary index tree traversal algorithm}

@chapter Optimizations

@section Elimination of n-times element lookup in full-vector operations (@code{fold}, @code{foldi}, @code{map})

Each index lookup takes @math{O(\log_m n)} steps, where @math{n} is the size of the vector and @math{m} is the branching factor.

However, for operations involving the entire vector, such as folds, mapping, and searches, we don't need to access each element by index. Instead, we can process entire leaves at once.

According to Jean Niklas L'Orange's master thesis@footnote{Improving RRB-Tree Performance through Transience by Jean Niklas L’Orange, Norwegian University of Science and Technology, 2014, pp.21--22, Theorem 2.5 (@url{https://hypirion.com/thesis.pdf})} the lookup of each leaf (32-element array in our case) in the tree has an amortised complexity of @math{O(1)}. Consequently, the entire operation has a complexity of @math{O(n)}, rather than the @math{O(n \log n)} complexity of a naïve solution.

@center @image{folds-before-optimization,409.6pt,286.8pt, fold performance before optimization}

@center @it{Performance of @code{fold} function before optimization.}

@center @image{folds,409.6pt,286.8pt, fold performance after optimization}

@center @it{Performance of @code{fold} function after optimization.}

@center @image{maps-before-optimization,409.6pt,286.8pt}

@center @it{Performance of @code{map} function before optimization.}

@center @image{maps,409.6pt,286.8pt}

@center @it{Performance of @code{map} function after optimization.}

@section Shortcut to tail

@center @image{pushes-before-optimization,512pt,358.5pt, pushes performance before optimization}

@center @image{pushes,512pt,358.5pt, pushes performance after optimization}

@include api/index.texi

@bye
